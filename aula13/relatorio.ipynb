{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 13 - SuperComp\n",
    "\n",
    "### Rodrigo Paoliello de Medeiros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schedules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Qual scheduler apresentou o menor tempo médio?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O scheduler static, apresentou o menor tempo de execução, com uma média de 2.57668e-06 segundos. Isso indica que uma granularidade mais fina pode ter contribuído para uma distribuição de carga mais eficiente entre as threads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Algum scheduler teve variações significativas entre as execuções? Se sim, por quê?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sim, os schedulers dynamic e guided apresentaram variações significativas tanto na distribuição das iterações entre as threads quanto nos tempos de execução. Essa variação é resultado da natureza adaptativa desses schedulers, que alocam iterações às threads durante a execução, ajustando-se à disponibilidade de recursos das threads em tempo real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Alguma característica específica do trabalho (como carga de dados, balanceamento) parece ter influenciado o comportamento de um scheduler em particular?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sim, a carga de dados e o balanceamento das iterações influenciaram o comportamento de certos schedulers. Os schedulers dynamic e guided se destacaram em tarefas com iterações de carga variável, ajustando a alocação de iterações de forma adaptativa para otimizar o desempenho. Já o scheduler static mostrou-se eficaz em cenários com iterações uniformes, beneficiando-se da distribuição equitativa e previsível, o que minimiza o overhead de gerenciamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo do PI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Qual abordagem (parallel for ou tasks) apresentou melhor desempenho?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A abordagem parallel for apresentou o melhor desempenho para o cálculo de Pi, com um tempo de execução de 1.352 segundos, comparado a 1.741 segundos da abordagem com tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. O valor de MIN_BLK ou o número de tarefas influenciou significativamente o tempo de execução?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sim, influências significativas foram observadas nas abordagens testadas. Na abordagem com parallel for, notou-se que ao aumentar o valor de MIN_BLK, o tempo de execução diminuiu ligeiramente, sugerindo que blocos de trabalho maiores reduziram a sobrecarga associada ao gerenciamento do paralelismo, tornando a execução mais eficiente. Por outro lado, na abordagem com tasks, os tempos de execução melhoraram à medida que o número de tarefas aumentou, especialmente ao passar de 16 para 64 tarefas. Isso indica que ter mais tarefas disponíveis para serem distribuídas entre as threads contribuiu para uma melhoria no desempenho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Alguma abordagem teve variação maior entre execuções? Por quê?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A abordagem com tasks mostrou maior variação nos tempos de execução entre diferentes execuções. Isso ocorre porque a distribuição dinâmica de carga nas tasks pode resultar em inconsistências no desempenho. Especificamente, quando o número de tasks é baixo, aumenta a probabilidade de desequilíbrio na distribuição de carga entre as threads, impactando a eficiência e a consistência dos resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulação de Efeitos Colaterais no Vetor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Qual abordagem teve melhor desempenho: omp critical ou pré-alocação de memória?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A abordagem com omp critical teve um desempenho superior, registrando tempos de execução inferiores aos da abordagem com pré-alocação de memória. Isso indica que, para o volume de dados e tipo de operação especificados, a região crítica não representou um gargalo significativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. O uso de omp critical adicionou muito overhead? Como você pode justificar isso?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O overhead introduzido pelo uso de omp critical foi baixo, conforme indicado pelos tempos de execução consistentemente reduzidos. Isso pode ser atribuído ao fato de que a operação dentro da região crítica (inserir elementos no vetor) é relativamente simples e o número total de elementos (N=10000) não foi suficiente para causar uma contenção significativa entre as threads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. A ordem dos dados no vetor foi mantida em ambas as abordagens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sim, em ambas as abordagens a ordem dos dados foi preservada. Com omp critical, as inserções no vetor foram sequenciais, garantindo a correta ordem de inserção dos elementos. Na pré-alocação de memória, cada thread foi responsável por um índice específico, mantendo a ordem ao escrever diretamente nos índices designados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Resuma as principais conclusões com base nos resultados obtidos nos testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As conclusões dos testes destacam diferenças significativas entre os schedulers e abordagens de paralelismo utilizadas:\n",
    "\n",
    "- Schedulers: O static mostrou-se o mais rápido, sugerindo eficácia em tarefas com iterações uniformes. Os dynamic e guided, embora mais lentos, adaptaram-se bem a cargas de trabalho variáveis, ajustando a alocação de iterações de maneira eficaz.\n",
    "\n",
    "- Cálculo de Pi: A abordagem parallel for foi mais eficiente que a abordagem com tasks, principalmente devido à gestão mais direta e menos sobrecarga de paralelismo.\n",
    "\n",
    "- Manipulação de vetores: A abordagem omp critical foi inesperadamente mais rápida que a pré-alocação de memória, indicando que as operações protegidas eram simples o suficiente para não causar um overhead notável."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Qual abordagem geral você considera mais eficiente para problemas recursivos e com efeitos colaterais?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para problemas recursivos e com efeitos colaterais, a abordagem parallel for parece ser geralmente mais eficiente quando aplicável, especialmente quando as tarefas podem ser claramente delineadas e não há dependências complexas entre elas. Esta abordagem reduz a sobrecarga de gerenciamento de tarefas e aproveita de forma mais eficiente os recursos do sistema. No entanto, para problemas onde as dependências entre as chamadas recursivas são mais intrincadas, a utilização de tasks pode oferecer maior flexibilidade e eficiência."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Alguma técnica apresentou resultados inesperados? O que poderia explicar isso?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A eficácia surpreendente do uso de omp critical no manejo de vetores foi um resultado inesperado, pois geralmente se espera que as regiões críticas adicionem um overhead considerável devido à serialização das operações. A explicação para isso pode estar na simplicidade das operações dentro da região crítica (apenas inserções em um vetor) e no tamanho moderado do vetor, que não foi grande o suficiente para criar uma contenção significativa. Isso sugere que para operações simples e conjuntos de dados de tamanho moderado, omp critical pode ser uma abordagem viável sem impactar negativamente o desempenho."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
